{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FlowerGenerator.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7o4iUl6gVvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from datetime import datetime as dt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a4B5Mrts6iC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "0756a585-21a6-4690-dc78-928a2dec9444"
      },
      "source": [
        "import os\n",
        "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n",
        "tf.config.experimental_connect_to_cluster(resolver)\n",
        "# This is the TPU initialization code that has to be at the beginning.\n",
        "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
        "print(\"All devices: \", tf.config.list_logical_devices('TPU'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.16.186.154:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.16.186.154:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b-vPJqVv3Uo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "0c6d4728-f90b-4b43-87d3-7519dbf8abfc"
      },
      "source": [
        "strategy = tf.distribute.experimental.TPUStrategy(resolver)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gw99jqv8gve9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4a1e1721-0013-4f3e-db0b-bb826937d54f"
      },
      "source": [
        "import os\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://github.com/mohmiim/MLIntroduction/raw/master/session-7/compressedData/flowers1.zip \\\n",
        "    -O /tmp/flowers1.zip\n",
        "!wget --no-check-certificate \\\n",
        "    https://github.com/mohmiim/MLIntroduction/raw/master/session-7/compressedData/flowers2.zip \\\n",
        "    -O /tmp/flowers2.zip\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://github.com/mohmiim/MLIntroduction/raw/master/session-7/compressedData/flowers3.zip \\\n",
        "    -O /tmp/flowers3.zip\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://github.com/mohmiim/MLIntroduction/raw/master/session-7/compressedData/flowers4.zip \\\n",
        "    -O /tmp/flowers4.zip\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-17 20:05:19--  https://github.com/mohmiim/MLIntroduction/raw/master/session-7/compressedData/flowers1.zip\n",
            "Resolving github.com (github.com)... 140.82.112.4\n",
            "Connecting to github.com (github.com)|140.82.112.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mohmiim/MLIntroduction/master/session-7/compressedData/flowers1.zip [following]\n",
            "--2020-06-17 20:05:19--  https://raw.githubusercontent.com/mohmiim/MLIntroduction/master/session-7/compressedData/flowers1.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 82761603 (79M) [application/zip]\n",
            "Saving to: ‘/tmp/flowers1.zip’\n",
            "\n",
            "/tmp/flowers1.zip   100%[===================>]  78.93M  89.2MB/s    in 0.9s    \n",
            "\n",
            "2020-06-17 20:05:21 (89.2 MB/s) - ‘/tmp/flowers1.zip’ saved [82761603/82761603]\n",
            "\n",
            "--2020-06-17 20:05:21--  https://github.com/mohmiim/MLIntroduction/raw/master/session-7/compressedData/flowers2.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mohmiim/MLIntroduction/master/session-7/compressedData/flowers2.zip [following]\n",
            "--2020-06-17 20:05:21--  https://raw.githubusercontent.com/mohmiim/MLIntroduction/master/session-7/compressedData/flowers2.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84953586 (81M) [application/zip]\n",
            "Saving to: ‘/tmp/flowers2.zip’\n",
            "\n",
            "/tmp/flowers2.zip   100%[===================>]  81.02M  93.0MB/s    in 0.9s    \n",
            "\n",
            "2020-06-17 20:05:23 (93.0 MB/s) - ‘/tmp/flowers2.zip’ saved [84953586/84953586]\n",
            "\n",
            "--2020-06-17 20:05:24--  https://github.com/mohmiim/MLIntroduction/raw/master/session-7/compressedData/flowers3.zip\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mohmiim/MLIntroduction/master/session-7/compressedData/flowers3.zip [following]\n",
            "--2020-06-17 20:05:24--  https://raw.githubusercontent.com/mohmiim/MLIntroduction/master/session-7/compressedData/flowers3.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85028220 (81M) [application/zip]\n",
            "Saving to: ‘/tmp/flowers3.zip’\n",
            "\n",
            "/tmp/flowers3.zip   100%[===================>]  81.09M  91.7MB/s    in 0.9s    \n",
            "\n",
            "2020-06-17 20:05:26 (91.7 MB/s) - ‘/tmp/flowers3.zip’ saved [85028220/85028220]\n",
            "\n",
            "--2020-06-17 20:05:26--  https://github.com/mohmiim/MLIntroduction/raw/master/session-7/compressedData/flowers4.zip\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mohmiim/MLIntroduction/master/session-7/compressedData/flowers4.zip [following]\n",
            "--2020-06-17 20:05:26--  https://raw.githubusercontent.com/mohmiim/MLIntroduction/master/session-7/compressedData/flowers4.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93643196 (89M) [application/zip]\n",
            "Saving to: ‘/tmp/flowers4.zip’\n",
            "\n",
            "/tmp/flowers4.zip   100%[===================>]  89.30M   100MB/s    in 0.9s    \n",
            "\n",
            "2020-06-17 20:05:28 (100 MB/s) - ‘/tmp/flowers4.zip’ saved [93643196/93643196]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCV_9YJZhzA_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile\n",
        "def unzip(file,target):\n",
        "  zip_ref = zipfile.ZipFile(file, 'r')\n",
        "  zip_ref.extractall(target)\n",
        "  zip_ref.close()\n",
        "\n",
        "unzip(\"/tmp/flowers1.zip\",\"/tmp/flowers\")\n",
        "unzip(\"/tmp/flowers2.zip\",\"/tmp/flowers\")\n",
        "unzip(\"/tmp/flowers3.zip\",\"/tmp/flowers\")\n",
        "unzip(\"/tmp/flowers4.zip\",\"/tmp/flowers\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WfCIGC7wlaBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "def load_samples(location = \"data/outline/\",width=112, height=112,mode='L') :\n",
        "  folder = location\n",
        "  size = (width,height)\n",
        "  onlyfiles = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
        "  data_set = np.zeros((len(onlyfiles), size[0], size[1], 3))\n",
        "  print(\"Working with {0} images\".format(len(onlyfiles)))\n",
        "  print(\"Image examples: \")\n",
        "  i=0\n",
        "  for _file in onlyfiles:\n",
        "    if i%100 == 0:\n",
        "      print('.',end=\"\")\n",
        "    img = Image.open(folder + _file).convert(mode) \n",
        "    img = img.resize(size)\n",
        "    x = img_to_array(img)  \n",
        "    data_set[i] = x\n",
        "    i = i +1\n",
        "  print(data_set.shape)\n",
        "  data_set = data_set.astype('float32')\n",
        "  data_set = (data_set - 127.5) / 127.5\n",
        "  return data_set    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHFbmiP1KfAm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import randn\n",
        "\n",
        "LATENT_DIM = 100\n",
        "\n",
        "def generate_latent_input(latentDim, count):\n",
        "  X = randn(latentDim * count)\n",
        "  X = X.reshape((count,latentDim))\n",
        "  X = X.astype('float32')\n",
        "  return X"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Cg4-eE-KfFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy import zeros\n",
        "def create_generated_samples(generator, latentDim, count):\n",
        "    X = generate_latent_input(latentDim, count)\n",
        "    gen_images = generator.predict(X)\n",
        "    # labels here will be fake ==> 0\n",
        "    y = zeros((count,1))\n",
        "    return gen_images, y"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6_JIS9LKfIn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from numpy.random import randint\n",
        "from numpy import ones\n",
        "\n",
        "def generate_real_samples(dataset, n_samples):\n",
        "    index = randint(0, dataset.shape[0], n_samples)\n",
        "    X = dataset[index]\n",
        "    # mark them as real\n",
        "    y = ones((n_samples, 1))\n",
        "    return X, y\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsU99aPNKfL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import LeakyReLU\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.initializers import RandomNormal \n",
        "\n",
        "DISC_FILTER_SIZE = 5\n",
        "DISC_LEAKY_ALPHA = 0.2 \n",
        "\n",
        "init = RandomNormal(stddev=0.02)\n",
        "def createDiscConvLayer(model):\n",
        "    model.add(Conv2D(128, (DISC_FILTER_SIZE,DISC_FILTER_SIZE),\n",
        "                     strides=(2, 2),\n",
        "                     padding='same',\n",
        "                     kernel_initializer=init))\n",
        "    model.add(LeakyReLU(alpha=DISC_LEAKY_ALPHA))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fbXoPzYKfOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dropout,Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "INPUT_SIZE = (80,80,3)\n",
        "DISC_DROPOUT = 0.4\n",
        "def create_discriminator(input_shape=INPUT_SIZE):\n",
        "    print(\"Creating Discriminator\")\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(40, (DISC_FILTER_SIZE,DISC_FILTER_SIZE),\n",
        "                      padding='same',\n",
        "                      kernel_initializer=init,\n",
        "                      input_shape=input_shape))\n",
        "    model.add(LeakyReLU(alpha=DISC_LEAKY_ALPHA))\n",
        "    # down sample to 40 X 40\n",
        "    createDiscConvLayer(model)\n",
        "    # down sample to 20 X 20\n",
        "    createDiscConvLayer(model)\n",
        "    # down sample to 10 X 10\n",
        "    createDiscConvLayer(model)\n",
        "    # down sample to 5 X 5\n",
        "    createDiscConvLayer(model)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dropout(DISC_DROPOUT))\n",
        "    activation = 'sigmoid'\n",
        "    loss= 'binary_crossentropy'\n",
        "    model.add(Dense(1, activation=activation))\n",
        "    # compile model\n",
        "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "    model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
        "    print(\"Created Discriminator\")\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dDXbJMyZmywx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9fc10f2a-e3f8-4632-8622-17e83dd6dfcc"
      },
      "source": [
        "dataset  = load_samples(\"/tmp/flowers/\", width=80, height=80, mode=\"RGB\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Working with 8189 images\n",
            "Image examples: \n",
            "..................................................................................(8189, 80, 80, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOXgNmWhorUQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "66e44377-3162-4325-dd69-0fe631e2440a"
      },
      "source": [
        "discriminator = create_discriminator()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Discriminator\n",
            "Created Discriminator\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 80, 80, 40)        3040      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 80, 80, 40)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 40, 40, 128)       128128    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 40, 40, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 20, 20, 128)       409728    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 20, 20, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 10, 10, 128)       409728    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 5, 5, 128)         409728    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 3201      \n",
            "=================================================================\n",
            "Total params: 1,363,553\n",
            "Trainable params: 1,363,553\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "084hvjdP1llH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Conv2DTranspose\n",
        "\n",
        "GEN_FILTER_SIZE = 5\n",
        "GEN_LEAKY_ALPHA = 0.2\n",
        "\n",
        "def addGenConvTransPoseLayer(model):\n",
        "  model.add(Conv2DTranspose(128, (GEN_FILTER_SIZE,GEN_FILTER_SIZE),\n",
        "                            strides=(2,2),\n",
        "                            padding='same'))\n",
        "  model.add(LeakyReLU(alpha=GEN_LEAKY_ALPHA))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGO6SQEY1y0m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Reshape\n",
        "\n",
        "def create_generator(latent_dim = LATENT_DIM):\n",
        "  print(\"Creating Genertor\")\n",
        "  model = Sequential()\n",
        "  # foundation for 64x64 image\n",
        "  n_nodes = 128 * 5 * 5\n",
        "  model.add(Dense(n_nodes, input_dim=latent_dim))\n",
        "  model.add(LeakyReLU(alpha=0.2))\n",
        "  model.add(Reshape((5, 5, 128)))\n",
        "  # up sacle to 10 * 10\n",
        "  addGenConvTransPoseLayer(model)\n",
        "  # upsample to 20*20\n",
        "  addGenConvTransPoseLayer(model)\n",
        "  # upsample to 40*40\n",
        "  addGenConvTransPoseLayer(model)\n",
        "  # upsample to 80*80\n",
        "  addGenConvTransPoseLayer(model)\n",
        "  # output layer\n",
        "  model.add(Conv2D(3, (5,5),\n",
        "                   activation='tanh',\n",
        "                   padding='same',\n",
        "                   kernel_initializer=init))\n",
        "  print(\"Created Generator\")\n",
        "  model.summary()\n",
        "  return model"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ME0m2ba63hgF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        },
        "outputId": "8ff3b21a-681f-480f-dba3-f28f9022ed46"
      },
      "source": [
        "generator = create_generator()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating Genertor\n",
            "Created Generator\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 3200)              323200    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 3200)              0         \n",
            "_________________________________________________________________\n",
            "reshape (Reshape)            (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose (Conv2DTran (None, 10, 10, 128)       409728    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 10, 10, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 20, 20, 128)       409728    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 20, 20, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTr (None, 40, 40, 128)       409728    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 40, 40, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 80, 80, 128)       409728    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 80, 80, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 80, 80, 3)         9603      \n",
            "=================================================================\n",
            "Total params: 1,971,715\n",
            "Trainable params: 1,971,715\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viLtnuEu4tq0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def create_gan(generator, discriminator):\n",
        "  print(\"Creating GAN\")\n",
        "  # freeze the weights of the discriminator\n",
        "  discriminator.trainable = False\n",
        "\n",
        "  # connect them\n",
        "  model = Sequential()\n",
        "  # add generator\n",
        "  model.add(generator)\n",
        "  # add the discriminator\n",
        "  model.add(discriminator)\n",
        "  # compile model\n",
        "  opt = Adam(lr=0.0002, beta_1=0.5)\n",
        "  loss= 'binary_crossentropy'\n",
        "  model.compile(loss=loss, optimizer=opt)\n",
        "  print(\"Created GAN\")\n",
        "  model.summary()\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSRM7jkk4t1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot\n",
        "\n",
        "def saveSamples(samples, epoch, n=5):\n",
        "    samples = (samples + 1) / 2.0\n",
        "    for i in range(n * n):\n",
        "        pyplot.subplot(n, n, 1 + i)\n",
        "        pyplot.axis('off')\n",
        "        pyplot.imshow(samples[i, :, :] )\n",
        "    pyplot.show()\n",
        "    pyplot.close()\n",
        "\n",
        "def generateSampleOutput(epoch, generator, n_samples=10):\n",
        "    X = generate_latent_input(LATENT_DIM, n_samples*n_samples)\n",
        "    y = generator.predict(X)\n",
        "    # save plot\n",
        "    saveSamples(y, epoch, n_samples)\n",
        "    # save the generator model tile file\n",
        "    filename = 'generator_model_%04d.h5' % (epoch + 1)\n",
        "    generator.save(filename)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-7tPoSJ4t4e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "n_epochs = 5 #500\n",
        "\n",
        "def train(generator, discriminator, gan, dataset, latent_dim, n_epochs=n_epochs, n_batch=256):\n",
        "  batches_count = math.ceil(dataset.shape[0] / n_batch)\n",
        "  half_batch = int(n_batch / 2)\n",
        "  # manually enumerate epochs\n",
        "  for i in range(n_epochs):\n",
        "    # enumerate batches over the training set\n",
        "    print(\" \")\n",
        "    print('>Epoch:%d' % (i+1), end = \" \")\n",
        "    t0 = dt.now()\n",
        "\n",
        "    for j in range(batches_count):\n",
        "      # get randomly selected 'real' samples\n",
        "      X_real, y_real = generate_real_samples(dataset, n_batch)\n",
        "      # generate 'fake' examples\n",
        "      X_fake, y_fake = create_generated_samples(generator, latent_dim, half_batch)\n",
        "      # update discriminator model weights\n",
        "      lossReal, _ = discriminator.train_on_batch(X_real, y_real)\n",
        "      lossFake, _ = discriminator.train_on_batch(X_fake, y_fake)\n",
        "      # prepare points in latent space as input for the generator\n",
        "      X_gan = generate_latent_input(latent_dim, n_batch)\n",
        "      # mark fake as real\n",
        "      y_gan = ones((n_batch, 1))\n",
        "      # update the generator via the discriminator's error\n",
        "      loss_generator = gan.train_on_batch(X_gan, y_gan)\n",
        "      print(\".\", end=\"\")\n",
        "      # summarize loss on this batch\n",
        "      \n",
        "    print(\"Finished training current epoch in ... : %.2f seconds\" % (dt.now()-t0).total_seconds())  \n",
        "\n",
        "    if i%10 == 0 :\n",
        "      generateSampleOutput(i+1,generator,4)\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQVQHlSh4t-2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "e0a9bd90-9c12-4b91-b6f9-58abe4b60a9f"
      },
      "source": [
        "# create the gan\n",
        "# Create the model, optimizer and metrics inside strategy scope, so that the\n",
        "# variables can be mirrored on each device.\n",
        "\n",
        "gan = create_gan(generator, discriminator)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating GAN\n",
            "Created GAN\n",
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_1 (Sequential)    (None, 80, 80, 3)         1971715   \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 1)                 1363553   \n",
            "=================================================================\n",
            "Total params: 3,335,268\n",
            "Trainable params: 1,971,715\n",
            "Non-trainable params: 1,363,553\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0iadDOh4uCT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3aecf125-3301-453f-f262-50f61bd23ef4"
      },
      "source": [
        "# train model\n",
        "t_start = dt.now()\n",
        "strategy.run(train(generator, discriminator, gan, dataset, LATENT_DIM))\n",
        "print(\"Finished training in  ... : %.2f seconds\" % (dt.now()-t0).total_seconds())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            ">Epoch:1 ..........."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ykSffrg4wG6q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}